{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7486d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: d:\\10academy\\week_4_building_an_amharic_e_commerce_data_extractor\n",
      "Raw Messages JSONL: d:\\10academy\\week_4_building_an_amharic_e_commerce_data_extractor\\data\\raw\\telegram_messages.jsonl\n",
      "Images Directory: d:\\10academy\\week_4_building_an_amharic_e_commerce_data_extractor\\data\\raw\\images\n",
      "Documents Directory: d:\\10academy\\week_4_building_an_amharic_e_commerce_data_extractor\\data\\raw\\documents\n"
     ]
    }
   ],
   "source": [
    "# notebooks/01_data_exploration.ipynb\n",
    "\n",
    "# ---  Import Libraries and Set Up Paths ---\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Adjust path based on notebook's location relative to project root\n",
    "# If this notebook is in 'notebooks/', then '..' goes to project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Import paths from config.py (ensure config.py is correctly set up)\n",
    "# Add project_root to sys.path to allow importing modules from 'scripts'\n",
    "import sys\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from scripts.config import RAW_MESSAGES_JSONL, RAW_DATA_DIR, IMAGES_DIR, DOCUMENTS_DIR\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Raw Messages JSONL: {RAW_MESSAGES_JSONL}\")\n",
    "print(f\"Images Directory: {IMAGES_DIR}\")\n",
    "print(f\"Documents Directory: {DOCUMENTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b72f22ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw scraped messages...\n",
      "Error: d:\\10academy\\week_4_building_an_amharic_e_commerce_data_extractor\\data\\raw\\telegram_messages.jsonl not found. Please run the data ingestion pipeline first.\n"
     ]
    }
   ],
   "source": [
    "# ---  Load Raw Scraped Data ---\n",
    "print(\"Loading raw scraped messages...\")\n",
    "raw_messages = []\n",
    "if os.path.exists(RAW_MESSAGES_JSONL):\n",
    "    with open(RAW_MESSAGES_JSONL, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                raw_messages.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Skipping malformed JSON line: {line.strip()} - Error: {e}\")\n",
    "    df_raw = pd.DataFrame(raw_messages)\n",
    "    print(f\"Loaded {len(df_raw)} messages.\")\n",
    "    if not df_raw.empty:\n",
    "        print(\"\\nFirst 5 rows of raw data:\")\n",
    "        display(df_raw.head())\n",
    "        print(\"\\nDataFrame Info:\")\n",
    "        df_raw.info()\n",
    "    else:\n",
    "        print(\"No messages loaded. The JSONL file might be empty or problematic.\")\n",
    "else:\n",
    "    print(f\"Error: {RAW_MESSAGES_JSONL} not found. Please run the data ingestion pipeline first.\")\n",
    "    df_raw = pd.DataFrame() # Create empty DataFrame to avoid errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad87562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- : Basic Data Overview ---\n",
    "if not df_raw.empty:\n",
    "    print(\"\\nBasic Statistics:\")\n",
    "    print(df_raw.describe(include='all', datetime_is_numeric=True))\n",
    "\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df_raw.isnull().sum())\n",
    "\n",
    "    print(\"\\nUnique Channels:\")\n",
    "    unique_channels = df_raw['channel_id'].nunique()\n",
    "    print(f\"Number of unique channels scraped: {unique_channels}\")\n",
    "\n",
    "    print(\"\\nMessages per Channel (Top 10):\")\n",
    "    messages_per_channel = df_raw['channel_id'].value_counts().head(10)\n",
    "    print(messages_per_channel)\n",
    "\n",
    "\n",
    "# --: Analyze Message Text Length ---\n",
    "if not df_raw.empty:\n",
    "    df_raw['text_length'] = df_raw['text'].fillna('').apply(len)\n",
    "    print(\"\\nText Length Distribution:\")\n",
    "    print(df_raw['text_length'].describe())\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df_raw['text_length'], bins=50, kde=True)\n",
    "    plt.title('Distribution of Message Text Lengths')\n",
    "    plt.xlabel('Text Length (Characters)')\n",
    "    plt.ylabel('Number of Messages')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ---  Analyze Media Presence ---\n",
    "if not df_raw.empty:\n",
    "    print(\"\\nMedia Presence:\")\n",
    "    media_counts = df_raw[['has_photo', 'has_document']].sum()\n",
    "    print(media_counts)\n",
    "\n",
    "    total_messages = len(df_raw)\n",
    "    messages_with_photo = df_raw['has_photo'].sum()\n",
    "    messages_with_document = df_raw['has_document'].sum()\n",
    "    messages_with_both = df_raw[(df_raw['has_photo'] == True) & (df_raw['has_document'] == True)].shape[0]\n",
    "\n",
    "    print(f\"\\nTotal messages: {total_messages}\")\n",
    "    print(f\"Messages with photos: {messages_with_photo} ({messages_with_photo/total_messages:.2%})\")\n",
    "    print(f\"Messages with documents: {messages_with_document} ({messages_with_document/total_messages:.2%})\")\n",
    "    print(f\"Messages with both photo and document: {messages_with_both}\")\n",
    "\n",
    "    # Check actual file existence for a sample\n",
    "    sample_media_check = df_raw.sample(min(100, len(df_raw)), random_state=42) # Sample up to 100 messages\n",
    "    existing_images = sample_media_check[sample_media_check['image_path'].notna()]['image_path'].apply(os.path.exists).sum()\n",
    "    existing_documents = sample_media_check[sample_media_check['document_path'].notna()]['document_path'].apply(os.path.exists).sum()\n",
    "\n",
    "    print(f\"\\nSample Check (100 messages) for downloaded media:\")\n",
    "    print(f\"Images existing on disk: {existing_images}\")\n",
    "    print(f\"Documents existing on disk: {existing_documents}\")\n",
    "    print(\"Note: 'File reference expired' errors during scraping mean the path exists in JSON but file does not.\")\n",
    "\n",
    "    # Visualize media presence\n",
    "    media_data = pd.DataFrame({\n",
    "        'Category': ['Messages with Photo', 'Messages with Document', 'Messages with Both', 'Messages with No Media'],\n",
    "        'Count': [\n",
    "            messages_with_photo,\n",
    "            messages_with_document,\n",
    "            messages_with_both,\n",
    "            total_messages - (messages_with_photo + messages_with_document - messages_with_both) # Correct no media count\n",
    "        ]\n",
    "    })\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(x='Category', y='Count', data=media_data)\n",
    "    plt.title('Distribution of Media in Messages')\n",
    "    plt.ylabel('Number of Messages')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Time Series Analysis (Messages over time) ---\n",
    "if not df_raw.empty:\n",
    "    df_raw['date_obj'] = pd.to_datetime(df_raw['date'])\n",
    "    df_raw['date_only'] = df_raw['date_obj'].dt.date\n",
    "    messages_per_day = df_raw['date_only'].value_counts().sort_index()\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    messages_per_day.plot(kind='line')\n",
    "    plt.title('Number of Messages Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of Messages')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nRecent messages (last 7 days):\")\n",
    "    last_7_days = messages_per_day.tail(7)\n",
    "    print(last_7_days)\n",
    "\n",
    "    print(\"\\nOldest and Newest Message Dates:\")\n",
    "    print(f\"Oldest: {df_raw['date_obj'].min()}\")\n",
    "    print(f\"Newest: {df_raw['date_obj'].max()}\")\n",
    "\n",
    "\n",
    "# ---  Sample Messages for Manual Inspection ---\n",
    "if not df_raw.empty:\n",
    "    print(\"\\n--- Sample Messages (with text and media status) ---\")\n",
    "    # Sample messages that have text and media\n",
    "    sample_text_media = df_raw[df_raw['text'].notna() & (df_raw['has_photo'] | df_raw['has_document'])].sample(min(5, len(df_raw)), random_state=1).to_dict('records')\n",
    "    print(\"\\nMessages with text and media:\")\n",
    "    for msg in sample_text_media:\n",
    "        print(f\"  ID: {msg['message_id']}, Date: {msg['date']}\")\n",
    "        print(f\"  Text: {msg['text'][:200]}...\") # Print first 200 chars\n",
    "        print(f\"  Has Photo: {msg['has_photo']}, Image Path: {msg['image_path']}\")\n",
    "        print(f\"  Has Document: {msg['has_document']}, Document Path: {msg['document_path']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # Sample messages with only text\n",
    "    sample_text_only = df_raw[df_raw['text'].notna() & ~df_raw['has_photo'] & ~df_raw['has_document']].sample(min(5, len(df_raw)), random_state=2).to_dict('records')\n",
    "    print(\"\\nMessages with text only:\")\n",
    "    for msg in sample_text_only:\n",
    "        print(f\"  ID: {msg['message_id']}, Date: {msg['date']}\")\n",
    "        print(f\"  Text: {msg['text'][:200]}...\")\n",
    "        print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
